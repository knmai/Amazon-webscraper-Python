{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "11e79a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from bs4 import BeautifulSoup as bs #helps get data from websites\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "import smtplib #library for sending emails to yourself \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "940083ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           Iberia Maduritos Naturally Sweet Plantain Chips, 20 Oz.\n",
      "          \n",
      "\n",
      "                      $6.50\n",
      "                      \n",
      "                       ($0.23 /  Ounce)\n",
      "                      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#connect to website\n",
    "\n",
    "URL= 'https://www.amazon.com/Iberia-Naturally-Sweet-Plantain-Chips/dp/B081LW6MWQ?pd_rd_w=90P0U&pf_rd_p=8e4731a7-b756-4530-8014-2f681a6d39bb&pf_rd_r=56K3EBV55YQZAEEVR4QN&pd_rd_r=a8802e7c-88d6-44ee-a92a-7babbd4e2c15&pd_rd_wg=iV0MY&pd_rd_i=B081LW6MWQ&psc=1&ref_=pd_bap_d_rp_1_i'\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.26 Safari/537.36\"} #used to identy your computer when connecting to page, When u don't add a user-agent, then website detects you as a bot and hence doesn't give you access to the website's contents. \n",
    "page = requests.get(URL, headers=headers)\n",
    "soup1 = bs(page.content,  \"lxml\") #calls html fle and stores it to be analyzed\n",
    "soup2 = bs(soup1.prettify(), \"lxml\") #formats the parsed html file and stores to be\n",
    "\n",
    "#title = soup2.find(id='productTitle') #finds defined id in html file in this case, the product title\n",
    "#price = soup2.find(id=\"sns-base-price\")#finds the product price\n",
    "#price = soup2.select(id='corePrice_Desktop', class_=\"a-offscreen\").get_text(\n",
    "\n",
    "#if title is None:\n",
    "#    print(\"Title not found in returned data\")\n",
    "#else:\n",
    "#    print(title.get_text())\n",
    "\n",
    "#if price is None:\n",
    "#    print(\"Title not found in returned data\")\n",
    "#else:\n",
    "#    print(price.get_text())\n",
    "\n",
    "title = soup2.find(id='productTitle').get_text() #finds defined id in html file in this case, the product title\n",
    "price = soup2.find(id='sns-base-price').get_text() #finds the product price\n",
    "\n",
    "\n",
    "if title is None:\n",
    "    print(\"No object found\")\n",
    "else:\n",
    "    print(title)\n",
    "\n",
    "if price is None:\n",
    "    print(\"No object found\")\n",
    "else:\n",
    "    print(price)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2e6ed429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iberia Maduritos Naturally Sweet Plantain Chips, 20 Oz.\n",
      "6.50\n"
     ]
    }
   ],
   "source": [
    "#Clean up extracted data\n",
    "price = price.strip()[1:5] #strip removes the extra space in extraxted text, [1:] tells it to skip the dollar sign, which is index 0, and write the rest\n",
    "title = title.strip()\n",
    "\n",
    "print(title)\n",
    "print(price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "61f85c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-17\n"
     ]
    }
   ],
   "source": [
    "today = datetime.date.today()\n",
    "\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d475a97a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'title' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\karln\\iCloudDrive\\DataScience Projects\\GitHub repos\\Amazon-webscraper-Python\\Web scrapper project(amazon).ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karln/iCloudDrive/DataScience%20Projects/GitHub%20repos/Amazon-webscraper-Python/Web%20scrapper%20project%28amazon%29.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39m#Create CSV file\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karln/iCloudDrive/DataScience%20Projects/GitHub%20repos/Amazon-webscraper-Python/Web%20scrapper%20project%28amazon%29.ipynb#ch0000004?line=2'>3</a>\u001b[0m header \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mTitle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPrice\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/karln/iCloudDrive/DataScience%20Projects/GitHub%20repos/Amazon-webscraper-Python/Web%20scrapper%20project%28amazon%29.ipynb#ch0000004?line=3'>4</a>\u001b[0m data \u001b[39m=\u001b[39m [title, price,today]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'title' is not defined"
     ]
    }
   ],
   "source": [
    "#Create CSV file\n",
    "\n",
    "header = ['Title', 'Price','Date']\n",
    "data = [title, price,today] #Creates a list with price and title as columns\n",
    "\n",
    "#with open('WebscraperDataset.csv', 'w', newline='',encoding='UTF8') as f:  #Creates a csv file and uses it as f\n",
    "    #writer = csv.writer(f) #Adds the data to csv file\n",
    "    #writer.writerow(header) #Uses header list as first row to write row titles\n",
    "    #writer.writerow(data) #Uses data as second list to write collected data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "bd85220f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  Price        Date\n",
      "0  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-17\n",
      "1  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-17\n",
      "2  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-17\n",
      "3  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-17\n",
      "4  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-17\n",
      "5  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-17\n",
      "6  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-17\n",
      "7  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-18\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('WebscraperDataset.csv') #turns csv data into dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "487c01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appends data to csv\n",
    "\n",
    "with open('WebscraperDataset.csv', 'a+', newline='',encoding='UTF8') as f:  #adding a+ in place of w means append\n",
    "    writer = csv.writer(f) \n",
    "    writer.writerow(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "7c334306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automatically checks for price changes\n",
    "\n",
    "def check_price():\n",
    "    URL= 'https://www.amazon.com/Iberia-Naturally-Sweet-Plantain-Chips/dp/B081LW6MWQ?pd_rd_w=90P0U&pf_rd_p=8e4731a7-b756-4530-8014-2f681a6d39bb&pf_rd_r=56K3EBV55YQZAEEVR4QN&pd_rd_r=a8802e7c-88d6-44ee-a92a-7babbd4e2c15&pd_rd_wg=iV0MY&pd_rd_i=B081LW6MWQ&psc=1&ref_=pd_bap_d_rp_1_i'\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.26 Safari/537.36\"}\n",
    "    page = requests.get(URL, headers=headers)\n",
    "    soup1 = bs(page.content,  \"lxml\") \n",
    "    soup2 = bs(soup1.prettify(), \"lxml\") \n",
    "    title = soup2.find(id='productTitle').get_text() \n",
    "    price = soup2.find(id='sns-base-price').get_text() \n",
    "    price = price.strip()[1:5] \n",
    "    title = title.strip()\n",
    "    today = datetime.date.today()\n",
    "    print(today)\n",
    "    header = ['Title', 'Price','Date']\n",
    "    data = [title, price,today] \n",
    "    with open('WebscraperDataset.csv', 'a+', newline='',encoding='UTF8') as f: \n",
    "        writer = csv.writer(f) \n",
    "        writer.writerow(data) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "0bcc1f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-18\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\karln\\Downloads\\Web scrapper project(amazon).ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karln/Downloads/Web%20scrapper%20project%28amazon%29.ipynb#ch0000008?line=0'>1</a>\u001b[0m \u001b[39mwhile\u001b[39;00m(\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/karln/Downloads/Web%20scrapper%20project%28amazon%29.ipynb#ch0000008?line=1'>2</a>\u001b[0m     check_price()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karln/Downloads/Web%20scrapper%20project%28amazon%29.ipynb#ch0000008?line=2'>3</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m5\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\karln\\Downloads\\Web scrapper project(amazon).ipynb Cell 8'\u001b[0m in \u001b[0;36mcheck_price\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karln/Downloads/Web%20scrapper%20project%28amazon%29.ipynb#ch0000007?line=4'>5</a>\u001b[0m soup1 \u001b[39m=\u001b[39m bs(page\u001b[39m.\u001b[39mcontent,  \u001b[39m\"\u001b[39m\u001b[39mlxml\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m#calls html fle and stores it to be analyzed\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karln/Downloads/Web%20scrapper%20project%28amazon%29.ipynb#ch0000007?line=5'>6</a>\u001b[0m soup2 \u001b[39m=\u001b[39m bs(soup1\u001b[39m.\u001b[39mprettify(), \u001b[39m\"\u001b[39m\u001b[39mlxml\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m#formats the parsed html file and stores to be\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/karln/Downloads/Web%20scrapper%20project%28amazon%29.ipynb#ch0000007?line=6'>7</a>\u001b[0m title \u001b[39m=\u001b[39m soup2\u001b[39m.\u001b[39;49mfind(\u001b[39mid\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mproductTitle\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mget_text() \u001b[39m#finds defined id in html file in this case, the product title\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karln/Downloads/Web%20scrapper%20project%28amazon%29.ipynb#ch0000007?line=7'>8</a>\u001b[0m price \u001b[39m=\u001b[39m soup2\u001b[39m.\u001b[39mfind(\u001b[39mid\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msns-base-price\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mget_text() \u001b[39m#finds the product price\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karln/Downloads/Web%20scrapper%20project%28amazon%29.ipynb#ch0000007?line=8'>9</a>\u001b[0m price \u001b[39m=\u001b[39m price\u001b[39m.\u001b[39mstrip()[\u001b[39m1\u001b[39m:\u001b[39m5\u001b[39m] \u001b[39m#strip removes the extra space in extraxted text, [1:] tells it to skip the dollar sign, which is index 0, and write the rest\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    check_price()\n",
    "    time.sleep(86400) #Checks and records price every day (it goes by seconds so 86k seconds in a day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "8e181824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  Price        Date\n",
      "0  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-17\n",
      "1  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-17\n",
      "2  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-17\n",
      "3  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-17\n",
      "4  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-17\n",
      "5  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-17\n",
      "6  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-17\n",
      "7  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-18\n",
      "8  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-18\n",
      "9  Iberia Maduritos Naturally Sweet Plantain Chip...    6.5  2022-04-18\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('WebscraperDataset.csv') #turns csv data into dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e5c207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0f614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a156290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007213a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e5e570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe8618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ea137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f77bdb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
